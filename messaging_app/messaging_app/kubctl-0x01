#!/bin/bash

# kubctl-0x01 - Kubernetes Scaling and Load Testing Script
set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Logging functions
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
log_warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }

# Configuration
DEPLOYMENT_NAME="django-messaging-app"
SERVICE_NAME="django-messaging-service"
TARGET_REPLICAS=3
LOAD_TEST_DURATION="30s"
LOAD_TEST_CONCURRENT=10
LOAD_TEST_THREADS=2

# Function to check prerequisites
check_prerequisites() {
    log_info "Checking prerequisites..."
    
    # Check if kubectl is available
    if ! command -v kubectl &> /dev/null; then
        log_error "kubectl is not installed or not in PATH"
        exit 1
    fi
    
    # Check if Kubernetes cluster is accessible
    if ! kubectl cluster-info &> /dev/null; then
        log_error "Cannot connect to Kubernetes cluster"
        log_info "Please ensure your cluster is running (minikube start)"
        exit 1
    fi
    
    # Check if deployment exists
    if ! kubectl get deployment $DEPLOYMENT_NAME &> /dev/null; then
        log_error "Deployment $DEPLOYMENT_NAME not found"
        log_info "Available deployments:"
        kubectl get deployments
        exit 1
    fi
    
    # Check current replica count
    CURRENT_REPLICAS=$(kubectl get deployment $DEPLOYMENT_NAME -o jsonpath='{.spec.replicas}')
    log_info "Current replica count: $CURRENT_REPLICAS"
}

# Function to scale the deployment
scale_deployment() {
    log_info "Scaling deployment $DEPLOYMENT_NAME to $TARGET_REPLICAS replicas..."
    
    # Scale the deployment
    kubectl scale deployment/$DEPLOYMENT_NAME --replicas=$TARGET_REPLICAS
    
    if [ $? -eq 0 ]; then
        log_success "Scaling command executed successfully"
    else
        log_error "Failed to scale deployment"
        exit 1
    fi
}

# Function to wait for pods to be ready
wait_for_pods() {
    log_info "Waiting for all pods to be ready..."
    
    local retries=30
    local count=0
    
    while [ $count -lt $retries ]; do
        READY_PODS=$(kubectl get deployment $DEPLOYMENT_NAME -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo "0")
        DESIRED_PODS=$(kubectl get deployment $DEPLOYMENT_NAME -o jsonpath='{.status.replicas}' 2>/dev/null || echo "0")
        
        if [ "$READY_PODS" = "$DESIRED_PODS" ] && [ "$DESIRED_PODS" = "$TARGET_REPLICAS" ]; then
            log_success "All $TARGET_REPLICAS pods are ready!"
            return 0
        fi
        
        log_info "Ready: ${READY_PODS:-0}/$TARGET_REPLICAS pods"
        sleep 5
        ((count++))
    done
    
    log_error "Timeout waiting for pods to be ready"
    log_info "Current pod status:"
    kubectl get pods -l app=django-messaging
    exit 1
}

# Function to verify multiple pods are running
verify_pods() {
    log_info "Verifying multiple pods are running..."
    
    echo -e "\n${BLUE}=== Current Pods ===${NC}"
    kubectl get pods -l app=django-messaging -o wide
    
    echo -e "\n${BLUE}=== Pod Distribution ===${NC}"
    kubectl get pods -l app=django-messaging -o jsonpath='{range .items[*]}{.metadata.name}{" - Node: "}{.spec.nodeName}{" - Status: "}{.status.phase}{" - IP: "}{.status.podIP}{"\n"}{end}'
    
    ACTUAL_PODS=$(kubectl get pods -l app=django-messaging --no-headers 2>/dev/null | grep -c "Running" || echo "0")
    if [ "$ACTUAL_PODS" -eq "$TARGET_REPLICAS" ]; then
        log_success "Verified: $ACTUAL_PODS pods are running"
    else
        log_error "Expected $TARGET_REPLICAS pods, but found $ACTUAL_PODS running"
        log_info "Pod details:"
        kubectl get pods -l app=django-messaging
        exit 1
    fi
}

# Function to setup service access for load testing
setup_service_access() {
    log_info "Setting up service access for load testing..."
    
    # Kill any existing port-forward processes
    pkill -f "kubectl port-forward" || true
    sleep 2
    
    # Start port-forward in background
    kubectl port-forward service/$SERVICE_NAME 8000:80 > /dev/null 2>&1 &
    PORT_FORWARD_PID=$!
    
    # Wait for port-forward to establish
    sleep 5
    
    # Check if port-forward is working
    if curl -s --connect-timeout 5 http://localhost:8000 > /dev/null 2>&1; then
        log_success "Service is accessible on http://localhost:8000"
    else
        log_warning "Service might not be responding directly. This might be normal if no root endpoint exists."
        log_info "We'll proceed with load testing on port 8000"
    fi
}

# Function to check and install wrk
install_wrk() {
    log_info "Checking for load testing tool 'wrk'..."
    
    if command -v wrk &> /dev/null; then
        log_success "wrk is already installed"
        return 0
    fi
    
    log_warning "wrk is not installed. Attempting to install..."
    
    # Try to install wrk based on OS
    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        if command -v apt-get &> /dev/null; then
            sudo apt-get update && sudo apt-get install -y wrk
        elif command -v yum &> /dev/null; then
            sudo yum install -y wrk
        else
            log_error "Cannot auto-install wrk on this Linux distribution"
            return 1
        fi
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        if command -v brew &> /dev/null; then
            brew install wrk
        else
            log_error "Homebrew not available. Please install wrk manually."
            return 1
        fi
    else
        log_error "Unsupported OS for auto-installation"
        return 1
    fi
    
    # Verify installation
    if command -v wrk &> /dev/null; then
        log_success "wrk installed successfully"
        return 0
    else
        log_error "Failed to install wrk"
        return 1
    fi
}

# Function to perform load testing
perform_load_test() {
    log_info "Preparing load testing..."
    
    # Install wrk if needed
    if ! install_wrk; then
        log_error "Please install wrk manually:"
        log_info "Ubuntu/Debian: sudo apt-get install wrk"
        log_info "macOS: brew install wrk"
        log_info "Then run this script again."
        return 1
    fi
    
    log_info "Starting load testing for $LOAD_TEST_DURATION..."
    log_info "Target: http://localhost:8000"
    log_info "Concurrent connections: $LOAD_TEST_CONCURRENT"
    log_info "Threads: $LOAD_TEST_THREADS"
    
    echo -e "\n${BLUE}=== Load Test Results ===${NC}"
    
    # Perform load test
    wrk -t$LOAD_TEST_THREADS -c$LOAD_TEST_CONCURRENT -d$LOAD_TEST_DURATION http://localhost:8000
    
    local wrk_exit_code=$?
    
    if [ $wrk_exit_code -eq 0 ]; then
        log_success "Load testing completed successfully"
    else
        log_warning "Load testing completed with exit code: $wrk_exit_code"
        log_info "This might be normal if the app doesn't have a root endpoint"
    fi
}

# Function to install metrics-server if needed
install_metrics_server() {
    log_info "Checking if metrics-server is installed..."
    
    if kubectl top nodes &> /dev/null; then
        log_success "metrics-server is already installed"
        return 0
    fi
    
    log_warning "metrics-server not available. Installing..."
    
    # Install metrics-server
    kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
    
    # Wait for metrics-server to be ready
    log_info "Waiting for metrics-server to start..."
    local retries=20
    local count=0
    
    while [ $count -lt $retries ]; do
        if kubectl get pods -n kube-system -l k8s-app=metrics-server --no-headers 2>/dev/null | grep -q "Running"; then
            log_success "metrics-server is running"
            
            # Wait a bit more for metrics to be available
            sleep 10
            return 0
        fi
        sleep 5
        ((count++))
    done
    
    log_error "metrics-server failed to start within timeout"
    return 1
}

# Function to monitor resource usage
monitor_resources() {
    log_info "Monitoring resource usage..."
    
    # Install metrics-server if needed
    if ! install_metrics_server; then
        log_error "Cannot monitor resources without metrics-server"
        return 1
    fi
    
    echo -e "\n${BLUE}=== Node Resource Usage ===${NC}"
    kubectl top nodes
    
    echo -e "\n${BLUE}=== Pod Resource Usage ===${NC}"
    kubectl top pods -l app=django-messaging
    
    echo -e "\n${BLUE}=== Detailed Resource Allocation ===${NC}"
    echo "Pod Name | CPU Request | CPU Limit | Memory Request | Memory Limit"
    echo "---------|-------------|-----------|----------------|--------------"
    
    kubectl get pods -l app=django-messaging -o jsonpath='{range .items[*]}{.metadata.name}{"|"}{.spec.containers[?(@.name=="django-app")].resources.requests.cpu}{"|"}{.spec.containers[?(@.name=="django-app")].resources.limits.cpu}{"|"}{.spec.containers[?(@.name=="django-app")].resources.requests.memory}{"|"}{.spec.containers[?(@.name=="django-app")].resources.limits.memory}{"\n"}{end}' 2>/dev/null | while read line; do
        if [ -n "$line" ]; then
            echo "$line" | sed 's/|/ | /g'
        fi
    done
}

# Function to display final summary
display_summary() {
    echo -e "\n${GREEN}=== Scaling and Load Testing Summary ===${NC}"
    
    echo -e "\n${BLUE}Final Deployment Status:${NC}"
    kubectl get deployment $DEPLOYMENT_NAME
    
    echo -e "\n${BLUE}Final Pod Status:${NC}"
    kubectl get pods -l app=django-messaging -o wide
    
    echo -e "\n${BLUE}Service Status:${NC}"
    kubectl get service $SERVICE_NAME
    
    log_success "Scaling completed: $TARGET_REPLICAS replicas running"
    log_success "Load testing performed: $LOAD_TEST_DURATION with $LOAD_TEST_CONCURRENT connections"
    log_success "Resource monitoring completed"
}

# Cleanup function
cleanup() {
    log_info "Cleaning up..."
    # Kill port-forward process
    if [ ! -z "$PORT_FORWARD_PID" ] && kill -0 $PORT_FORWARD_PID 2>/dev/null; then
        kill $PORT_FORWARD_PID 2>/dev/null
        log_info "Stopped port-forwarding"
    fi
    # Kill any other kubectl port-forward processes
    pkill -f "kubectl port-forward" || true
}

# Main execution function
main() {
    log_info "Starting Kubernetes scaling and load testing script..."
    
    # Set up cleanup on exit
    trap cleanup EXIT
    
    # Step 1: Check prerequisites
    check_prerequisites
    
    # Step 2: Scale the deployment
    scale_deployment
    
    # Step 3: Wait for pods to be ready
    wait_for_pods
    
    # Step 4: Verify multiple pods are running
    verify_pods
    
    # Step 5: Setup service access
    setup_service_access
    
    # Step 6: Perform load testing
    perform_load_test
    
    # Step 7: Monitor resource usage
    monitor_resources
    
    # Display final summary
    display_summary
    
    log_success "Script execution completed successfully!"
}

# Run main function
main "$@"